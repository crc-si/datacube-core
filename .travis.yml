dist: trusty
sudo: false  # Use the new travis docker based infrastructure

git:
  # We need a deeper depth for 'git descibe' to ensure
  # we can reach the last tagged version.
  depth: 99999

language: python
python:
  - "3.5"
  - "3.6"

cache:
  directories:
    - $HOME/.cache/pip

# Install required packages
addons:
  # We typically use postgres 9.6, but Travis has 9.5 pre-installed, so the build goes a little faster
  postgresql: "9.5"
  services:
    - postgresql
    - redis-server
  apt:
    sources:
      - sourceline: ppa:nextgis/ppa
    packages:
      - gdal-bin
      - libgdal-dev
      - libgdal20
      - libudunits2-0

before_install:
# Create a database for the integration tests.
  - createdb agdcintegration

# Check disk usage
  - df -h
  - df -i

# Set paths for building python-gdal
  - export CPLUS_INCLUDE_PATH=/usr/include/gdal
  - export C_INCLUDE_PATH=/usr/include/gdal
  - pip install coveralls


install:
# Install datacube
  - pip install '.[test,analytics,celery,s3]' --upgrade
  - pip install ./tests/drivers/fail_drivers --no-deps --upgrade  # used to test exception paths in driver loader

# Print installed packages in case we need to debug them
  - pip freeze

# Check disk usage
  - df -h
  - df -i

script:
# Ensure we are running against the correct python version
  - '[[ $(python --version 2>&1) == *"$TRAVIS_PYTHON_VERSION"* ]]'

# Run all the linting and tests
  - ./check-code.sh integration_tests

after_success:
  - test $TRAVIS_PYTHON_VERSION = "3.6" && coveralls

before_deploy:
  - python setup.py sdist --dist-dir dist/$TRAVIS_PYTHON_VERSION
  - DEPLOY_PATH=$TRAVIS_REPO_SLUG/${TRAVIS_TAG:-$TRAVIS_BRANCH}  # eg opendatacube/datacube-core/datacube-1.4.2

# On success, upload a package to an S3 Bucket. Used for continuous deployment.
deploy:
  # Deploy the source dist tarball to s3 for tags or the develop branch, so that it can be installed on other systems
  # For tags, the object will be opendatacube/datacube-core/datacube-1.4.2/3.6/datacube-1.4.2.tar.gz
  # For develop, the object will be opendatacube/datacube-core/develop/3.6/datacube-1.4.1+91.g43bd4e12.tar.gz
  - provider: s3
    access_key_id: "AKIAJMZN4F5L5KXPQKVQ"
    secret_access_key:
      secure: owxrrQc4i1jfAwvASFewdMzNdi93zpwnoEhsTJQS/f3SkD083XpefUr4H7Mg8cZiq5grT6NpoYkG6QDoxz30Kn5IbDIHewRy3I11uwz02JGUkzxv+/7hLOnoM/LM993WWXA+YQJmrO4HvncDy3Hgbw98xkKOeqsQ1XlYR8Lp5NUQnwJtLkouOJYfJSU/ZuIyetYC3bO2JkF/smtEPmVPJ8ZJjAQEqCdiUJsvMWKDlDh+cLOKM6EBTorE8GTECfMY+HUy74nH7xdkJ2xQm6PjO2wJVtcgCW377Jfn7IJqMhmlhA6fnkguyb58S5NkwwSynFizm7GidtbAxTeaIHimB3B6ImWUQu/maiWrWpMZGyqoC+l3+zQ/jg5Pam9Crtff8odFNT/tvwVGMTxuVkUxYRZ87XGM+G4D29xV/FGs0oqyn3Jw4SPXmg1bBymJOwmL+YogYFvJAR77MmbBUcf6SCogJzvI4Z2IFe9afMCbZaNeSD1GGh+EYCjJIKrpc9sY2ZxON1Mgv1bQ9FnSrDxyCUYEsshh8x9AaAFcYdGRGc6V0IT/5gopH3gf+XC+Q2OQHGC5oiaJ0+R4BoT3YuxEYfpBHvrpWk30Ug8C9ZgxoGK2xjabKiJ/2LlKe+xHoe77ZWZCkc1RocZnSHFBaFgaQrzppWsty04WGHl5fIVgH1Q=
    bucket: "datacube-core-deployment"
    region: "ap-southeast-2"
    local_dir: dist
    upload_dir: $DEPLOY_PATH
    skip_cleanup: true
    on:
      all_branches: true  # Let the condition below decide if the branch is to be deployed
      condition: $TRAVIS_BRANCH = "develop" || ! -z "${TRAVIS_TAG}"  # develop branch or tags
      repo: opendatacube/datacube-core
      python: "3.6"

notifications:
  slack:
    on_success: change
    on_failure: always
    on_pull_requests: false
    rooms:
      secure: kUlIXKlqxpnfNwJxgZdLy5XtfeYnc5Iq+OdvtyMFBJ94Iw3gP64KH8C/pUPqJblwiINj/vi5AF1TSaVG5VgSVF5zwEhAa4Ad0V9OZvsfJuLoE5/nFvkCdXeOU70/aMitF5SG7x6Q9LYhDqUDtS/XyGy48f2eiXN0Sa6/3KGQbyFXRvMDQercNR8LXXXjJZ0VjMsUD2Zl5FVy3FMHItVUTVlyMiBc/1fPJiSxOPz8ySSjeANnKuFIQN7/h+IbIrEVIJh8/T8SkOpuYceXBosr4HDfcTt3mFp0gT4Gc4TvYIjN/ykzomSY2+fkr0txSb7ao7+ZZvZ6XWfB6A/MnGNbmwSFmYX5fbBs493ErsIrCealsqvtyE2lvAj58vOv/5sFtBcD9d2hPUCCm345D7TGh6KMrSELfg4fhTiGfg181I6ZdQUR6veb9H1aPmE2Kh+XnZOaGP/uI7GkUeCRH92pPPjWf6/7YdxwFTsgggKxdE3FZVwYjO6DJBJ12iuXcOVz6MFXCpeiYNZPzXBtCF+tngGS9NEG6/CM1wP5CfbJEEbYXB0eL+qRQRkCgzYKQgvtreOfsfbMP1Oi2vBTq/JfdY888B3HVXJxUm1RPAAw4DsynbKzyCqoRECz6+X2zCR7i5DlcoEKuKURRA9DA0WPnMqUHAJsUS2n7jj58ANHo0o=
